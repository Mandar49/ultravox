# SLM with ultravox & llama3.1, trained wtih knowledge distillation.

# Make sure to accept the license agreement on huggingface hub
text_model: "meta-llama/Meta-Llama-3.1-8B-Instruct"
audio_model: "openai/whisper-medium"

# device: "cpu"
# data_type: "float32"

loss_config:
  # Choose from ["KL_Divergence", "CrossEntropy"], default is "KL_Divergence"
  loss_function: "KL_Divergence"

max_steps: 10 # x8x24 = 2,764,800

train_dataset_args:
  shuffle: True
  batch_size: 24

train_dataset_configs:
# continuation
  - path: "fixie-ai/librispeech_asr"
    name: "clean"
    splits:
      - "train.100" # 28_539 samples
      - "train.360" # 104_014 samples
    num_samples: 132_553
    user_template: "Continue the following text using less than 50 words:\n\n<|audio|>"
    assistant_template: "{{ continuation }}"
    transcript_template: "{{ text }}"
    weight: 1