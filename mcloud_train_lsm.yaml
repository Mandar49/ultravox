# Ultravox training configuration
name: train-lsm
image: mosaicml/composer:latest
compute:
  gpus: 8
  cluster: r15z1p1
integrations:
  - integration_type: git_repo
    git_repo: fixie-ai/ultravox-omni
    git_branch: $UV_BRANCH
    pip_install: poetry==1.7.1
scheduling:
  max_duration: 20  # LSM training is slower, so we give it 20 hours
command: >-
  cd ultravox-omni &&
  poetry install --no-dev &&
  poetry run python -m ultravox.training.helpers.prefetch_weights $TRAIN_ARGS &&
  poetry run torchrun --nproc_per_node=8 -m ultravox.training.train $TRAIN_ARGS
env_variables:
  MLFLOW_TRACKING_URI: databricks
  UV_BRANCH: main
  TRAIN_ARGS: --config_path ultravox/training/configs/lsm.yaml
  HF_HUB_ENABLE_HF_TRANSFER: 1